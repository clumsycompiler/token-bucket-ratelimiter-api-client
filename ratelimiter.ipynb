{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import csv\n",
    "import nba_api\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "import requests\n",
    "from aiohttp import ClientSession, TCPConnector\n",
    "import random\n",
    "import math\n",
    "from contextlib import asynccontextmanager\n",
    "import numpy as np\n",
    "import itertools\n",
    "import backoff_utils\n",
    "from backoff_utils import backoff\n",
    "from backoff_utils import apply_backoff\n",
    "from backoff_utils import strategies\n",
    "import backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers for the request\n",
    "# used nba.com as an example\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:100.0) Gecko/20100101 Firefox/100.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'x-nba-stats-origin': 'stats',\n",
    "    'x-nba-stats-token': 'true',\n",
    "    'Origin': 'https://www.nba.com',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://www.nba.com/',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'Pragma': 'no-cache',\n",
    "    'Cache-Control': 'no-cache',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate limiter class for limiting the number of resquests per second\n",
    "#max no of tokens is the rate limit\n",
    "class RateLimiter:\n",
    "    def __init__(self,rate_limit: int,concurrency_limit: int) -> None:\n",
    "        #rate limit = no of request per second, rps\n",
    "        self.rate_limit = rate_limit\n",
    "        self.tokens_queue = asyncio.Queue(rate_limit)\n",
    "        #consume tokens from queue at constant rate\n",
    "        self.tokens_consumer_task = asyncio.create_task(self.consume_tokens())\n",
    "        self.semaphore = asyncio.Semaphore(concurrency_limit)\n",
    "    #\n",
    "    async def add_token(self) -> None:\n",
    "        await self.tokens_queue.put(1)\n",
    "        return None\n",
    "    async def consume_tokens(self):\n",
    "        try:\n",
    "            consumption_rate = 1 / self.rate_limit\n",
    "            last_consumption_time = 0\n",
    "            while True:\n",
    "                if self.tokens_queue.empty():\n",
    "                    await asyncio.sleep(consumption_rate)\n",
    "                    continue\n",
    "\n",
    "                current_consumption_time = time.monotonic()\n",
    "                total_tokens = self.tokens_queue.qsize()\n",
    "                tokens_to_consume = self.get_tokens_amount_to_consume(\n",
    "                    consumption_rate,\n",
    "                    current_consumption_time,\n",
    "                    last_consumption_time,\n",
    "                    total_tokens\n",
    "                )\n",
    "                for i in range(0, tokens_to_consume):\n",
    "                    self.tokens_queue.get_nowait()\n",
    "\n",
    "                last_consumption_time = time.monotonic()\n",
    "\n",
    "                await asyncio.sleep(consumption_rate)\n",
    "        except asyncio.CancelledError:\n",
    "            # you can ignore the error here and deal with closing this task later but this is not advised\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            # do something with the error and re-raise\n",
    "            raise\n",
    "    @staticmethod\n",
    "    def get_tokens_amount_to_consume(consumption_rate, current_consumption_time, last_consumption_time, total_tokens):\n",
    "        #time btwn iteration\n",
    "        time_from_last_consumption = current_consumption_time - last_consumption_time\n",
    "        \n",
    "        calculated_tokens_to_consume = math.floor(time_from_last_consumption / consumption_rate)\n",
    "        tokens_to_consume = min(total_tokens, calculated_tokens_to_consume)\n",
    "        return tokens_to_consume\n",
    "    @asynccontextmanager\n",
    "    async def throttle(self):\n",
    "        await self.semaphore.acquire()\n",
    "        await self.add_token()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            self.semaphore.release()\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        if exc_type:\n",
    "            # log error here and safely close the class\n",
    "            pass\n",
    "\n",
    "        await self.close()\n",
    "\n",
    "    async def close(self) -> None:\n",
    "        if self.tokens_consumer_task and not self.tokens_consumer_task.cancelled():\n",
    "            try:\n",
    "                self.tokens_consumer_task.cancel()\n",
    "                await self.tokens_consumer_task\n",
    "            except asyncio.CancelledError:\n",
    "                # we ignore this exception but it is good to log and signal the task was cancelled\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                # log here and deal with the exception\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines the method of retrying failed requests and timeouts for quiting\n",
    "@backoff.on_exception(backoff.expo,\n",
    "                      aiohttp.ClientError, max_time=60 )  \n",
    "@backoff.on_exception(backoff.expo,\n",
    "                      asyncio.TimeoutError ,\n",
    "                      max_time=300)   \n",
    "# sends the actual requests   \n",
    "async def send_request(lock,game_id,  client_session: aiohttp.ClientSession , rate_limiter: RateLimiter):\n",
    "    start1= time.time()\n",
    "    async with rate_limiter.throttle():\n",
    "        # use the desired url here\n",
    "        url = f'https://stats.nba.com/stats/boxscorefourfactorsv2?EndPeriod=1&EndRange=0&GameID={game_id}&RangeType=0&StartPeriod=1&StartRange=0'\n",
    "        print(f'sending url: {url}')\n",
    "        end1= time.time()-start1\n",
    "        print(end1)\n",
    "        start = time.time()\n",
    "        timeout = aiohttp.ClientTimeout(total=None,connect=None,sock_connect=None, sock_read=None)\n",
    "        response =await client_session.get(url, headers = headers, timeout=timeout)\n",
    "        print(f'releasing throttler')\n",
    "    # Why are the following lines not included in the rate limiter context?\n",
    "    # because all we want to control is the rate of io operations\n",
    "    # and since the following lines instruct reading the response stream into memory,\n",
    "    # it shouldn't block the next requests from sending\n",
    "    # (unless you have limited memory or large files to ingest.\n",
    "    # In that case you should add it to the context \n",
    "    # but also make sure you free memory for the next requests)!\n",
    "    # so we should now release the semaphore and let the\n",
    "    # stream reading begin async while letting the rest of the requests go on sending\n",
    "    print(f'reading stream of response from {url}')    \n",
    "    roundtrip = time.time()-start\n",
    "    print(roundtrip)\n",
    "    status = response.status\n",
    "    print(status)\n",
    "    #retries the 504 code using expnl backoff algo\n",
    "    if status == 504:\n",
    "        response =  await client_session.get(url, headers = headers, timeout=timeout)\n",
    "    else:\n",
    "        pass\n",
    "    data = await response.read()\n",
    "    # hashrate is the json data\n",
    "    hashrate = json.loads(data)\n",
    "    response.json(content_type=None)\n",
    "    response.release()\n",
    "    return hashrate\n",
    "\n",
    "# calls the ratelimiter class to be used with the send requests function\n",
    "async def send_multiple_requests(lock):\n",
    "    async with RateLimiter(rate_limit=9, concurrency_limit=10) as rate_limiter:\n",
    "        async with aiohttp.ClientSession(raise_for_status=True) as session:\n",
    "            tasks = [asyncio.ensure_future(send_request(lock, client_session=session,rate_limiter=rate_limiter))]\n",
    "            return await asyncio.gather(*tasks)\n",
    "\n",
    "#lock is used to control the asynch loop\n",
    "# providing the funtionanlity of stopping the loop on exception\n",
    "async def main():\n",
    "    lock= asyncio.Lock()\n",
    "    return await send_multiple_requests(lock)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
